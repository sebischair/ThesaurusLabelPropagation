{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import random\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_file = \"<PROJECT_DIR>/08_propagation_evaluation/<DATE>/main.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    evaluation_file,\n",
    "    sep=\" \",\n",
    "    index_col=0)\n",
    "\n",
    "if len(df[(df.y_train == -1) & (df.y_test == -1) & (df.y_pred == -1)]) != 0:\n",
    "    print(\"WARNING\")\n",
    "else:\n",
    "    print(\"All right\")\n",
    "\n",
    "df_evaluation = df.sort_index()\n",
    "\n",
    "df_evaluation = df_evaluation[[\"y_train\", \"y_pred\", \"y_conf\"]]\n",
    "df_evaluation.head()\n",
    "print(df_evaluation.shape)\n",
    "df_evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = df_evaluation.y_train[df_evaluation.y_train != -1].value_counts().to_frame()\n",
    "pred_counts = df_evaluation.y_pred.value_counts().to_frame()\n",
    "counts = train_counts.join(pred_counts)\n",
    "print(counts.shape)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_quantil = 0.10\n",
    "mid_quantilA = 0.45\n",
    "mid_quantilB = 0.55\n",
    "high_quantil = 0.90\n",
    "\n",
    "# counts.y_train[y_train_low]\n",
    "y_train_low = counts.y_train <= counts.y_train.quantile(q=low_quantil)\n",
    "print(\"y_train_low\", np.sum(y_train_low))\n",
    "y_train_mid = (counts.y_train >= counts.y_train.quantile(q=mid_quantilA)) & (counts.y_train <= counts.y_train.quantile(q=mid_quantilB))\n",
    "print(\"y_train_mid\", np.sum(y_train_mid))\n",
    "y_train_high = counts.y_train >= counts.y_train.quantile(q=high_quantil)\n",
    "print(\"y_train_high\", np.sum(y_train_high))\n",
    "\n",
    "print()\n",
    "\n",
    "y_pred_low = counts.y_pred <= counts.y_pred.quantile(q=low_quantil)\n",
    "print(\"y_pred_low\", np.sum(y_pred_low))\n",
    "y_pred_mid = (counts.y_pred >= counts.y_pred.quantile(q=mid_quantilA)) & (counts.y_pred <= counts.y_pred.quantile(q=mid_quantilB))\n",
    "print(\"y_pred_mid\", np.sum(y_pred_mid))\n",
    "y_pred_high = counts.y_pred >= counts.y_pred.quantile(q=high_quantil)\n",
    "print(\"y_pred_high\", np.sum(y_pred_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the synsets into the nine groups (where a synset can appear in multiple groups)\n",
    "# y_train, y_pred\n",
    "\n",
    "# group1: low, low\n",
    "g1_mask = pd.concat((y_train_low, y_pred_low), axis=1)\n",
    "g1 = counts[g1_mask].dropna()\n",
    "print(g1.shape)\n",
    "\n",
    "# group2: low, mid\n",
    "g2_mask = pd.concat((y_train_low, y_pred_mid), axis=1)\n",
    "g2 = counts[g2_mask].dropna()\n",
    "print(g2.shape)\n",
    "\n",
    "# group3: low, high\n",
    "g3_mask = pd.concat((y_train_low, y_pred_high), axis=1)\n",
    "g3 = counts[g3_mask].dropna()\n",
    "print(g3.shape)\n",
    "\n",
    "# group4: mid, low\n",
    "g4_mask = pd.concat((y_train_mid, y_pred_low), axis=1)\n",
    "g4 = counts[g4_mask].dropna()\n",
    "print(g4.shape)\n",
    "\n",
    "# group5: mid, mid\n",
    "g5_mask = pd.concat((y_train_mid, y_pred_mid), axis=1)\n",
    "g5 = counts[g5_mask].dropna()\n",
    "print(g5.shape)\n",
    "\n",
    "# group6: mid, high\n",
    "g6_mask = pd.concat((y_train_mid, y_pred_high), axis=1)\n",
    "g6 = counts[g6_mask].dropna()\n",
    "print(g6.shape)\n",
    "\n",
    "# group7: high, low\n",
    "g7_mask = pd.concat((y_train_high, y_pred_low), axis=1)\n",
    "g7 = counts[g7_mask].dropna()\n",
    "print(g7.shape)\n",
    "\n",
    "# group8: high, mid\n",
    "g8_mask = pd.concat((y_train_high, y_pred_mid), axis=1)\n",
    "g8 = counts[g8_mask].dropna()\n",
    "print(g8.shape)\n",
    "\n",
    "# group9: high, high\n",
    "g9_mask = pd.concat((y_train_high, y_pred_high), axis=1)\n",
    "g9 = counts[g9_mask].dropna()\n",
    "print(g9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take three synsets per groups\n",
    "# If a synset was already taken by another group, repeat process\n",
    "num_try = 0\n",
    "while True:\n",
    "    print(\"Try:\", num_try)\n",
    "    samples = [group.sample(n=3) \n",
    "               for group in [g1, g2, g3, g4, g5, g6, g7, g8, g9]]\n",
    "    pp.pprint([sample.index.tolist() for sample in samples])\n",
    "\n",
    "    # check if every synset only occurrs one time\n",
    "    flat_list = [item for sample in samples for item in sample.index.tolist()]\n",
    "    if len(set(flat_list)) != 27:\n",
    "        print(\"A synset occurred multiple times! \",len(set(flat_list)),\", Trying again...\")\n",
    "        num_try += 1\n",
    "    else: \n",
    "        print(\"Found distinct samples\")\n",
    "        pp.pprint([sample.index.tolist() for sample in samples])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell(_df, _synset_row, _conf_order):\n",
    "    training = df_evaluation[df_evaluation.y_train == _synset_row.Index].index.tolist()\n",
    "    s = df_evaluation[(df_evaluation.y_train != df_evaluation.y_pred) & (df_evaluation.y_pred == _synset_row.Index)][[\"y_conf\"]]\n",
    "    s = s.reset_index()\n",
    "    \n",
    "    if _conf_order == \"high_first\":\n",
    "        s = s.sort_values(by=\"y_conf\", ascending=False)\n",
    "    elif _conf_order == \"low_first\":\n",
    "        s = s.sort_values(by=\"y_conf\", ascending=True)\n",
    "    elif _conf_order == \"random\":\n",
    "        s = s.sample(frac=1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    s = s.head(10)\n",
    "    suggestions = [{\"word\": r.word, \"conf\": r.y_conf} for r in s.itertuples()]\n",
    "\n",
    "    return {\n",
    "        \"synset\": _synset_row.Index,\n",
    "        \"training\": training,\n",
    "        \"suggestions\": suggestions,\n",
    "        \"remark\": \"conf_order: {}, y_train: {}, y_pred: {}\".format(_conf_order, _synset_row.y_train, _synset_row.y_pred)\n",
    "    }\n",
    "\n",
    "cells = [] # to display in Excel\n",
    "conf_orders = [\"high_first\", \"low_first\", \"random\"]\n",
    "\n",
    "# Sort the suggestions wihin the three synsets per group according to confidence\n",
    "for sample in samples:\n",
    "    for synset_row, conf_order in zip(sample.itertuples(), conf_orders):\n",
    "        cells.append(create_cell(df_evaluation, synset_row, conf_order))\n",
    "    \n",
    "pp.pprint(cells[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: Write into an Excel file\n",
    "eval_scoring_file = \"thesaurus_suggestor_\" + datetime.datetime.today().strftime(\n",
    "    '%Y%m%d-%H%M%S') + \".xlsx\"\n",
    "print(\"Evaluation Scoring File: \", eval_scoring_file)\n",
    "\n",
    "workbook = xlsxwriter.Workbook(eval_scoring_file)\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "italic = workbook.add_format({'italic': True})\n",
    "bold = workbook.add_format({'bold': True})\n",
    "gray_bg = workbook.add_format({'bg_color': '#D8D8D8'})\n",
    "two_dec_dig = workbook.add_format()\n",
    "two_dec_dig.set_num_format('0.00')\n",
    "\n",
    "worksheet.write('A3', 'generation time')\n",
    "worksheet.write('B3', datetime.datetime.today().strftime('%Y%m%d-%H%M%S'))\n",
    "worksheet.write('A4', 'evaluation_file')\n",
    "worksheet.write('B4', evaluation_file)\n",
    "\n",
    "row = 6\n",
    "col = 1\n",
    "\n",
    "worksheet.write(row, col, \"Existing Synset\", bold)\n",
    "worksheet.set_column(col, col,  22)\n",
    "worksheet.write(row, col + 3, \"Suggestion\", bold)\n",
    "worksheet.set_column(col + 3, col + 3,  22)\n",
    "worksheet.write(row, col + 4, \"Confidence\", bold)\n",
    "worksheet.set_column(col + 4, col + 4,  10)\n",
    "worksheet.write(row, col + 5, \"Score (worst: 0, best: 2)\", bold)\n",
    "\n",
    "row = row + 1\n",
    "\n",
    "for idx, case in enumerate(cells):\n",
    "    row_start = row\n",
    "\n",
    "    worksheet.write(row, col-1, case[\"synset\"])\n",
    "    worksheet.write_comment(row, col-1, \"g{}, \".format((idx//3)+1)+case[\"remark\"])\n",
    "\n",
    "    for word in case[\"training\"]:\n",
    "        worksheet.write(row, col, word)\n",
    "        row = row + 1\n",
    "        \n",
    "    row = row_start\n",
    "\n",
    "    for rank, suggestion in enumerate(case[\"suggestions\"], start=1):\n",
    "        worksheet.write(row, col + 2, rank)\n",
    "\n",
    "        worksheet.write(row, col + 3, suggestion[\"word\"])\n",
    "\n",
    "        worksheet.write(row, col + 4, suggestion[\"conf\"], two_dec_dig)\n",
    "        worksheet.write(row, col + 5, '', gray_bg)\n",
    "        row = row + 1\n",
    "\n",
    "    row = row + 2\n",
    "\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
